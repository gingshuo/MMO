{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participle：\n",
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      ".\n",
      "\n",
      "Part of speech tag：\n",
      "Apple: PROPN\n",
      "is: AUX\n",
      "looking: VERB\n",
      "at: ADP\n",
      "buying: VERB\n",
      "U.K.: PROPN\n",
      "startup: NOUN\n",
      "for: ADP\n",
      "$: SYM\n",
      "1: NUM\n",
      "billion: NUM\n",
      ".: PUNCT\n",
      "\n",
      "Lemmatization：\n",
      "Apple: Apple\n",
      "is: be\n",
      "looking: look\n",
      "at: at\n",
      "buying: buy\n",
      "U.K.: U.K.\n",
      "startup: startup\n",
      "for: for\n",
      "$: $\n",
      "1: 1\n",
      "billion: billion\n",
      ".: .\n",
      "\n",
      "Named entity recognition：\n",
      "Apple: ORG\n",
      "U.K.: GPE\n",
      "$1 billion: MONEY\n",
      "\n",
      "Syntactic analysis：\n",
      "Apple: nsubj -> looking\n",
      "is: aux -> looking\n",
      "looking: ROOT -> looking\n",
      "at: prep -> looking\n",
      "buying: pcomp -> at\n",
      "U.K.: dobj -> buying\n",
      "startup: dep -> looking\n",
      "for: prep -> startup\n",
      "$: quantmod -> billion\n",
      "1: compound -> billion\n",
      "billion: pobj -> for\n",
      ".: punct -> looking\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英语模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 输入文本\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(text)\n",
    "\n",
    "# 分词\n",
    "print(\"Participle：\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "# 词性标注\n",
    "print(\"\\nPart of speech tag：\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_}\")\n",
    "\n",
    "# 词形还原\n",
    "print(\"\\nLemmatization：\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.lemma_}\")\n",
    "\n",
    "# 命名实体识别\n",
    "print(\"\\nNamed entity recognition：\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_}\")\n",
    "\n",
    "# 句法解析\n",
    "print(\"\\nSyntactic analysis：\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.dep_} -> {token.head.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
